# convert shitty factor types
for(j in 1:ncol(links@data)){links@data[,j]=as.numeric(as.character(links@data[,j]))}
warnings()
links@data$maxspeed
for(l in 1:length(links)){
#show(l)
#currentAdditionalAttrs=as.numeric(as.character(links@data[l,e_attr_names]))
currentAdditionalAttrs=links@data[l,e_attr_names]
#show(currentAdditionalAttrs)
for(i in 1:length(links@lines[[l]]@Lines)){
coords = links@lines[[l]]@Lines[[i]]@coords
vids = c()
#mincoords=apply(stations@coords,1,function(r){l=links@lines[[l]]@Lines[[i]]@coords;return(min(apply(abs(l-matrix(data=rep(r,nrow(l)),ncol=2,byrow = TRUE)),1,function(r){sqrt(r[1]^2+r[2]^2)})))})
for(k in 1:nrow(coords)){
if(nrow(vertexes)>0){
statdist = apply(vertexes[,c("x","y")] - matrix(rep(coords[k,],nrow(vertexes)),ncol=2,byrow=TRUE),1,function(r){sqrt(r[1]^2+r[2]^2)})
}else{statdist=c(2*snap)}
if(statdist[statdist==min(statdist)]<snap){
vids=append(vids,vertexes$id[statdist==min(statdist)])
#show(paste0('existing : ',vids))
}else{
# else create new vertex
vids=append(vids,currentvid)
#show(paste0('new : ',vids))
vertexes=rbind(vertexes,c(id=currentvid,x=coords[k,1],y=coords[k,2],station=FALSE))
names(vertexes)<-c("id","x","y","station")
currentvid=currentvid+1
}
#show(vertexes)
}
# add edges
for(k in 2:nrow(coords)){
addedge=c(from=vids[k-1],
to=vids[k],
speed=speed,
length=sqrt((coords[k-1,1]-coords[k,1])^2+(coords[k-1,2]-coords[k,2])^2),
currentAdditionalAttrs
)
#show(addedge)
edges=rbind(edges,addedge)
}
}
}
edges
e_attr_names = c("maxspeed")
edges = data.frame()
edges$from=as.character(edges$from);edges$to=as.character(edges$to)
for(l in 1:length(links)){
#show(l)
#currentAdditionalAttrs=as.numeric(as.character(links@data[l,e_attr_names]))
currentAdditionalAttrs=links@data[l,e_attr_names]
#show(currentAdditionalAttrs)
for(i in 1:length(links@lines[[l]]@Lines)){
coords = links@lines[[l]]@Lines[[i]]@coords
vids = c()
#mincoords=apply(stations@coords,1,function(r){l=links@lines[[l]]@Lines[[i]]@coords;return(min(apply(abs(l-matrix(data=rep(r,nrow(l)),ncol=2,byrow = TRUE)),1,function(r){sqrt(r[1]^2+r[2]^2)})))})
for(k in 1:nrow(coords)){
if(nrow(vertexes)>0){
statdist = apply(vertexes[,c("x","y")] - matrix(rep(coords[k,],nrow(vertexes)),ncol=2,byrow=TRUE),1,function(r){sqrt(r[1]^2+r[2]^2)})
}else{statdist=c(2*snap)}
if(statdist[statdist==min(statdist)]<snap){
vids=append(vids,vertexes$id[statdist==min(statdist)])
#show(paste0('existing : ',vids))
}else{
# else create new vertex
vids=append(vids,currentvid)
#show(paste0('new : ',vids))
vertexes=rbind(vertexes,c(id=currentvid,x=coords[k,1],y=coords[k,2],station=FALSE))
names(vertexes)<-c("id","x","y","station")
currentvid=currentvid+1
}
#show(vertexes)
}
# add edges
for(k in 2:nrow(coords)){
addedge=c(from=vids[k-1],
to=vids[k],
speed=speed,
length=sqrt((coords[k-1,1]-coords[k,1])^2+(coords[k-1,2]-coords[k,2])^2),
currentAdditionalAttrs
)
#show(addedge)
edges=rbind(edges,addedge)
}
}
}
edges
snap = 1e-6
edges = data.frame()
currentvid = ifelse(nrow(vertexes)>0,as.numeric(as.character(vertexes$id))[nrow(vertexes)] + 1,1)
edges$from=as.character(edges$from);edges$to=as.character(edges$to)
for(l in 1:length(links)){
#show(l)
#currentAdditionalAttrs=as.numeric(as.character(links@data[l,e_attr_names]))
currentAdditionalAttrs=links@data[l,e_attr_names]
#show(currentAdditionalAttrs)
for(i in 1:length(links@lines[[l]]@Lines)){
coords = links@lines[[l]]@Lines[[i]]@coords
vids = c()
#mincoords=apply(stations@coords,1,function(r){l=links@lines[[l]]@Lines[[i]]@coords;return(min(apply(abs(l-matrix(data=rep(r,nrow(l)),ncol=2,byrow = TRUE)),1,function(r){sqrt(r[1]^2+r[2]^2)})))})
for(k in 1:nrow(coords)){
if(nrow(vertexes)>0){
statdist = apply(vertexes[,c("x","y")] - matrix(rep(coords[k,],nrow(vertexes)),ncol=2,byrow=TRUE),1,function(r){sqrt(r[1]^2+r[2]^2)})
}else{statdist=c(2*snap)}
if(statdist[statdist==min(statdist)]<snap){
vids=append(vids,vertexes$id[statdist==min(statdist)])
#show(paste0('existing : ',vids))
}else{
# else create new vertex
vids=append(vids,currentvid)
#show(paste0('new : ',vids))
vertexes=rbind(vertexes,c(id=currentvid,x=coords[k,1],y=coords[k,2],station=FALSE))
names(vertexes)<-c("id","x","y","station")
currentvid=currentvid+1
}
#show(vertexes)
}
# add edges
for(k in 2:nrow(coords)){
addedge=c(from=vids[k-1],
to=vids[k],
speed=speed,
length=sqrt((coords[k-1,1]-coords[k,1])^2+(coords[k-1,2]-coords[k,2])^2),
currentAdditionalAttrs
)
#show(addedge)
edges=rbind(edges,addedge)
}
}
}
edges
help(simplify)
comblist=list(speed="mean",length="sum")
for(attrname in e_attr_names){comblist[[attrname]]="min"}
res = simplify(graph_from_data_frame(edges,directed=FALSE,vertices = vertexes),edge.attr.comb = comblist)
g = induced_subgraph(res,which(degree(res)>0))
if(is.null(stations_layer)){
V(g)$station = rep(TRUE,vcount(g))
}
g
g
res = simplify(graph_from_data_frame(edges,directed=FALSE,vertices = vertexes),edge.attr.comb = comblist)
res
vertexes
graph_from_data_frame(edges,directed=FALSE,vertices = vertexes)
comblist
#show(edges)
names(edges)<-c("from","to","speed","length",e_attr_names)
comblist=list(speed="mean",length="sum")
for(attrname in e_attr_names){comblist[[attrname]]="min"}
res = simplify(graph_from_data_frame(edges,directed=FALSE,vertices = vertexes),edge.attr.comb = comblist)
res
g = induced_subgraph(res,which(degree(res)>0))
if(is.null(stations_layer)){
V(g)$station = rep(TRUE,vcount(g))
}
g
# source: addTransportationLayer in CS_HOME/CityNetwork/Models/TransportationNetwork/NetworkAnalysis/network.R
source(paste0(Sys.getenv('CS_HOME'),"/CityNetwork/Models/TransportationNetwork/NetworkAnalysis/network.R"))
nw = addTransportationLayer(link_layer = roads$osm_lines, snap=1e-6)
nw
shortest_paths(nw,from = V(nw)[1])
install.packages('r5r')
citation()
help(facet_grid)
library(ggplot2)
help(facet_grid)
remotes::install_github("mdneuzerling/getsysreqs")
install.packages('remote')
install.packages('remotes')
vignette(remote)
library(remote)
help(remote)
library(remotes)
remotes::install_github("mdneuzerling/getsysreqs")
getsysreqs("devtools")
library(getsysreqs)
get_sysreqs("devtools")
library(devtools)
install.packages("devtools")
library(devtools)
install.packages("ragg")
install.packages("devtools")
library(devtools)
install.packages('remotes')
library(remotes)
remotes::install_github("sebastien-plutniak/archeofrag")
(help(remotes))
help(remotes)
help("remotes")
library(remotes)
help(remotes)
help(install.packages)
library(osmdata)
library(sf)
# routes principales pour Paris
bb <- getbb('paris fr', format_out = 'polygon')
# exporter en sp (pour utilisation avec des packages non compatibles avec sf)
roads <- opq(bbox = bb, timeout = 200) %>% add_osm_feature(key='highway',value='primary') %>% osmdata_sp()
# transformer les donnees brutes en graphe igraph pour calculer des temps de parcours
#  -> fonctions disponible ici : https://github.com/JusteRaimbault/TransportationNetwork (pas encore déployé en package)
source('https://raw.githubusercontent.com/JusteRaimbault/TransportationNetwork/master/NetworkAnalysis/network.R')
# dans notre cas une seule couche de transport
#  (pour le snapping = aggregation des noeuds, ici les donnees ne sont pas projetees, on aggrege a 100m ~)
g <- addTransportationLayer(link_layer = roads$osm_lines, snap = 0.001)
roads
# transformer les donnees brutes en graphe igraph pour calculer des temps de parcours
#  -> fonctions disponible ici : https://github.com/JusteRaimbault/TransportationNetwork (pas encore déployé en package)
source('https://raw.githubusercontent.com/JusteRaimbault/TransportationNetwork/master/NetworkAnalysis/network.R')
# dans notre cas une seule couche de transport
#  (pour le snapping = aggregation des noeuds, ici les donnees ne sont pas projetees, on aggrege a 100m ~)
g <- addTransportationLayer(link_layer = roads$osm_lines, snap = 0.001)
warnings()
g
summary(E(g)$length)
summary(V(g)$x)
summary(V(g)$y)
# plot d'un plus court chemin aleatoire (vitesse constante = 1 -> a adapter a une vitesse reelle)
path = shortest_paths(g, from = sample.int(vcount(g),1), to = sample.int(vcount(g),1),weights = 1/E(g)$length)
plot(g, vertex.size=5, vertex.label=NA,
vertex.color = ifelse(V(g)%in%path$vpath[[1]],'green', 'black')
)
# plot d'un plus court chemin aleatoire (vitesse constante = 1 -> a adapter a une vitesse reelle)
path = shortest_paths(g, from = sample.int(vcount(g),1), to = sample.int(vcount(g),1),weights = 1/E(g)$length)
plot(g, vertex.size=5, vertex.label=NA,
vertex.color = ifelse(V(g)%in%path$vpath[[1]],'green', 'black')
)
# plot d'un plus court chemin aleatoire (vitesse constante = 1 -> a adapter a une vitesse reelle)
path = shortest_paths(g, from = sample.int(vcount(g),1), to = sample.int(vcount(g),1),weights = 1/E(g)$length)
plot(g, vertex.size=5, vertex.label=NA,
vertex.color = ifelse(V(g)%in%path$vpath[[1]],'green', 'black')
)
# plot d'un plus court chemin aleatoire (vitesse constante = 1 -> a adapter a une vitesse reelle)
path = shortest_paths(g, from = sample.int(vcount(g),1), to = sample.int(vcount(g),1),weights = 1/E(g)$length)
plot(g, vertex.size=5, vertex.label=NA,
vertex.color = ifelse(V(g)%in%path$vpath[[1]],'green', 'black')
)
# plot d'un plus court chemin aleatoire (vitesse constante = 1 -> a adapter a une vitesse reelle)
path = shortest_paths(g, from = sample.int(vcount(g),1), to = sample.int(vcount(g),1),weights = 1/E(g)$length)
plot(g, vertex.size=5, vertex.label=NA,
vertex.color = ifelse(V(g)%in%path$vpath[[1]],'green', 'black')
)
# plot d'un plus court chemin aleatoire (vitesse constante = 1 -> a adapter a une vitesse reelle)
path = shortest_paths(g, from = sample.int(vcount(g),1), to = sample.int(vcount(g),1),weights = 1/E(g)$length)
plot(g, vertex.size=5, vertex.label=NA,
vertex.color = ifelse(V(g)%in%path$vpath[[1]],'green', 'black')
)
# fonctions pour simplifier le graphe
source('https://github.com/JusteRaimbault/TransportationNetwork/raw/master/NetworkSimplification/nwSimplFunctions.R')
install.packages(RMongo)
install.packages("RMongo")
library(ggplot2)
library(dplyr)
match_data <-  read.csv("./2020_LoL_esports_match_data_from_OraclesElixir_20210124.csv")
cor.test(match_data_num$dpm, match_data_num$earned.gpm,method = spearman)
library(ggplot2)
library(dplyr)
match_data <-  read.csv("./2020_LoL_esports_match_data_from_OraclesElixir_20210124.csv")
match_data_num <- (match_data %>% select(where(is.numeric)))
head(match_data_num)
match_data_num <-  select(match_data_num,-c(year, playoffs,patch, playerid, game, result))
match_data_num = match_data_num[match_data$position!="team",]
match_data_num = match_data_num[,!apply(match_data_num,MARGIN=2,anyNA)]
cormat = cor(match_data_num)
cor.test(match_data_num$dpm, match_data_num$earned.gpm,method = spearman)
cor.test(match_data_num$dpm, match_data_num$earned.gpm,method = "spearman")
cor(match_data_num$dpm, match_data_num$earned.gpm,method = "spearman")
cor(match_data_num$dpm, match_data_num$earned.gpm)
cor(match_data_num, method = "spearman")
abs(cor(match_data_num, method = "spearman") - cor(match_data_num))
cordiff =abs(cor(match_data_num, method = "spearman") - cor(match_data_num))
max(cordiff)
ggplot(match_data_num)+geom_point(aes(earned.gpm,monsterkillsownjungle),size=0.1)
ggplot(match_data_num)+geom_point(aes(total.cs,monsterkillsownjungle),size=0.1)
lm(data=match_data_num, dpm ~ earned.gpm)
model = lm(data=match_data_num, dpm ~ earned.gpm)
summary(model)
cor(match_data_num$earned.gpm,match_data_num$dpm)
coefficients(model)
names(model)
names(summary(model))
match_data$result
chisq.test(match_data$result, match_data$position)
chisq.test(match_data$result, match_data$champion)
chisq.test(match_data$result,match_data$earned.gpm < 500)
summary(match_data$earned.gpm)
chisq.test(match_data$result,match_data$quadrakills>0)
help(chisq)
help(chisq.test)
View(match_data)
chisq.test(match_data$result[match_data$league=="TCL"], match_data$champion[match_data$league=="TCL"])
chisq.test(match_data$result[match_data$league=="VCS"], match_data$champion[match_data$league=="VCS"])
library(dplyr)
library(ggplot2)
library(ade4)
library(factoextra)
library(palmerpenguins)
data("penguins")
head(penguins)
p <- penguins[!apply(penguins,MARGIN = 1,anyNA),]
library(corrplot)
names(p)
p <- penguins[!apply(penguins,MARGIN = 1,anyNA),c("bill_length_mm","bill_depth_mm","flipper_length_mm","body_mass_g")]
corrplot(cor(p))
library(GGally)
install.packages("GGally")
install.packages("~/Bureau/tmp_R/GGally_2.2.1.tar.gz", repos = NULL, type = "source")
install.packages("~/Bureau/tmp_R/ggstats_0.7.0.tar.gz", repos = NULL, type = "source")
p <- penguins[!apply(penguins,MARGIN = 1,anyNA),]
dataACP <- p %>% select(bill_length_mm,bill_depth_mm,flipper_length_mm,body_mass_g)
apply(dataACP,MARGIN = 2,var)
sum(apply(dataACP,MARGIN = 2,var))
trace(cov(dataACP))
sum(diag(cov(dataACP)))
help(dudi.pca)
prcomp(dataACP)
summary(prcomp(dataACP))
apply(dataACP,MARGIN = 2,var)
summary(prcomp(dataACP,scale. = T))
summary(prcomp(dataACP,scale. = T,center = T))
fancy_pca <- dudi.pca(dataACP)
fancy_pca <- dudi.pca(dataACP)
fancy_pca <- dudi.pca(df = dataACP, scannf = FALSE, nf = NA)
fancy_pca <- dudi.pca(df = dataACP, scannf = FALSE, nf = 2)
fancy_pca
fviz_eig(fancy_pca)
help(fviz_pca_var)
pca <- prcomp(dataACP,scale. = T)
summary(pca)
fviz_pca_var(pca)
fviz_pca_ind(pca)
fviz_pca_biplot(fancy_pca)
get_pca_ind(fancy_pca)
get_pca_ind(fancy_pca)$coord
fviz_pca_var(pca)
fviz_pca_ind(pca)
get_pca_ind(fancy_pca)
inds = cbind(get_pca_ind(fancy_pca)$coord,p[,c("species","island","sex","year")])
ggplot(inds)+geom_point(aes(x=Dim.1,y=Dim.2,color=island))
ggplot(inds)+geom_point(aes(x=Dim.1,y=Dim.2,color=species))
ggplot(inds)+geom_point(aes(x=Dim.1,y=Dim.2,color=sex))
ggplot(inds)+geom_point(aes(x=Dim.1,y=Dim.2,color=year))
ggplot(inds)+geom_point(aes(x=Dim.1,y=Dim.2,color=species))
fviz_pca_var(pca)
summary(pca)
pca$rotation
fviz_pca_ind(fancy_pca,axes = c(1, 2) )
fviz_pca_ind(fancy_pca,axes = c(3, 4))
fviz_pca_ind(pca,axes = c(3, 4))
variable_continue <-  rnorm(10000, 10,5)
help(cut)
cuts = cut(x,k)
x = variable_continue
k=10
cuts = cut(x,k)
cuts
levels(cuts)
counts = rep(0,k)
names(counts) = levels(cuts)
counts
for(xx in as.character(cuts)){counts[xx] = counts[xx]+1}
counts
mode <- function(x,k){
cuts = cut(x,k)
counts = rep(0,k)
names(counts) = levels(cuts)
for(xx in as.character(cuts)){counts[xx] = counts[xx]+1}
return(names(counts)[counts==max(counts)])
}
mode(variable_continue)
variable_continue <-  rnorm(1000000, 10,5)
mode(variable_continue,100)
mode(variable_continue,10)
mode(variable_continue,50)
help(mode)
help(hist)
valeurs <-  rnorm(50,mean = 20, sd=1) #50 échantillons dans une loi normale
valeurs
valeurs %>% round() %>% mean()
head(starwars)
variable_continue <-  rnorm(1000000, 10,5)
mode <- function(x,k){
cuts = cut(x,k)
counts = rep(0,k)
names(counts) = levels(cuts)
for(xx in as.character(cuts)){counts[xx] = counts[xx]+1}
return(names(counts)[counts==max(counts)])
}
mode(variable_continue,50)
library(dplyr)
valeurs <-  rnorm(50,mean = 20, sd=1) #50 échantillons dans une loi normale
valeurs
valeurs %>% round() %>% mean()
library(knitr)
head(starwars[,1:11]) %>%  kable()
filter(starwars, height < 100)
filter(starwars, height < 100)[,1:11] %>% kable()
library(knitr)
head(starwars[,1:11]) %>%  kable()
starwars[ starwars$height < 100 , ]
help(dplyr::filter)
help("dplyr::filter")
help(filte)
help(filter)
# en dplyr
starwars %>% filter(height >= 180, species=="Human")
starwars %>% filter(species=="Human", homeworld=="Tatooine") %>% slice_max(order_by=height)
starwars %>% filter(species=="Human", homeworld=="Tatooine") %>% slice_max(order_by=height,n = 3)
starwars %>% group_by(homeworld)
starwars %>% filter(gender=="masculine") %>%
group_by(homeworld) %>%
summarise(mean_size=mean(height, na.rm=T),sd_size = sd(height, na.rm=T))
starwars %>% filter(gender=="masculine") %>%
group_by(homeworld) %>%
summarise(count = n(), mean_size=mean(height, na.rm=T),sd_size = sd(height, na.rm=T))
starwars %>% filter(gender=="masculine") %>%
group_by(homeworld) %>%
summarise(count = n(), mean_size=mean(height, na.rm=T),sd_size = sd(height, na.rm=T)) %>% filter(count >1)
help(arrange)
starwars %>% filter (height >150) %>%
group_by(homeworld,species) %>%
summarise( nombre = n()) %>%  na.omit() %>%
arrange(-nombre)
starwars %>%
group_by(homeworld,species) %>%
mutate( nombre = n(),
classe_taille= ifelse(height>140, "grand", "petit")
) %>%
select(homeworld,species,nombre,classe_taille)
doublons <- starwars %>% select(homeworld, species)
doublons
doublons %>%  distinct()
library(readr)
library(sf)
library(dplyr)
library(mapsf)
rawdvf2024 <- read_csv(file = 'https://files.data.gouv.fr/geo-dvf/latest/csv/2024/full.csv.gz')
install.packages("osmdata")
setwd(paste0(Sys.getenv('CS_HOME'),'/uantitativeEpistemology/GeoTheoQuantIntegration/Models/KDIntegration'))
setwd(paste0(Sys.getenv('CS_HOME'),'/QuantitativeEpistemology/GeoTheoQuantIntegration/Models/KDIntegration'))
install.packages("igraph")
library(dplyr, warn.conflicts = F)
library(igraph, warn.conflicts = F)
library(glue)
library(reshape2)
library(ggplot2)
install.packages("heatmaply")
install.packages("heatmaply")
library(dplyr, warn.conflicts = F)
library(igraph, warn.conflicts = F)
library(glue)
library(reshape2)
library(ggplot2)
library(heatmaply)
source(paste0(Sys.getenv('CS_HOME'),'/Organisation/Models/Utils/R/plots.R'))
source('functions.R')
edge_file = '../../Data/Corpuses/evurbth_links.csv'
node_file = '../../Data/Corpuses/evurbth.csv'
edges <- read.csv(edge_file,sep=";",header=F,colClasses = c('character','character'))
nodes <- as_tibble(read.csv(node_file,sep=";",stringsAsFactors = F,quote = '"',colClasses = rep('character',4)))
nodes[,3]=as.numeric(unlist(nodes[,3])) # year
nodes[,4]=as.numeric(unlist(nodes[,4])) # depth
citation <- graph_from_data_frame(edges,vertices = nodes)
citation
components(citation)$csize
citation = induced_subgraph(citation,which(components(citation)$membership==1))
V(citation)$reduced_title = sapply(V(citation)$title,function(s){paste0(substr(s,1,30),"...")})
V(citation)$reduced_title = ifelse(degree(citation)>50,V(citation)$reduced_title,rep("",vcount(citation)))
citationcorehigher = induced_subgraph(citation,which(degree(citation)>1))
while(length(which(degree(citationcorehigher)==1))>0){citationcorehigher = induced_subgraph(citationcorehigher,which(degree(citationcorehigher)>1))}
citationcorehigher = induced_subgraph(citation,which(degree(citation)>2))
while(length(which(degree(citationcorehigher)==1))>0){citationcorehigher = induced_subgraph(citationcorehigher,which(degree(citationcorehigher)>1))}
while(length(which(degree(citationcorehigher)==1))>0){citationcorehigher = induced_subgraph(citationcorehigher,which(degree(citationcorehigher)>1))}
V(g)
V(citationcorehigher)
citationcorehigher
citation
citationcorehigher
# export
export_gml(citationcorehigher,'../../Data/Processed/core_evurbth.gml')
citation <- graph_from_data_frame(edges,vertices = nodes)
citation = induced_subgraph(citation,which(components(citation)$membership==1))
# keep at least degree 3 (-> 1252 to annotate)
citationcorehigher = induced_subgraph(citation,which(degree(citation)>2))
while(length(which(degree(citationcorehigher)==1))>0){citationcorehigher = induced_subgraph(citationcorehigher,which(degree(citationcorehigher)>1))}
export_gml <- function(citnw,exportfile){
V(citnw)$reduced_title = sapply(V(citnw)$title,function(s){paste0(substr(s,1,50),"...")})
V(citnw)$reduced_title = ifelse(degree(citnw)>20,V(citnw)$reduced_title,rep("",vcount(citnw)))
# remove empty attributes
for(attr in c('depth','citingFilled',kws)){
if(attr %in% vertex_attr_names(citnw)){
citnw = delete_vertex_attr(citnw,attr)
}
}
write_graph(citnw,file=exportfile,format = 'gml')
}
# export
export_gml(citationcorehigher,'../../Data/Processed/core_evurbth.gml')
export_gml <- function(citnw,exportfile, kws=c()){
V(citnw)$reduced_title = sapply(V(citnw)$title,function(s){paste0(substr(s,1,50),"...")})
V(citnw)$reduced_title = ifelse(degree(citnw)>20,V(citnw)$reduced_title,rep("",vcount(citnw)))
# remove empty attributes
for(attr in c('depth','citingFilled',kws)){
if(attr %in% vertex_attr_names(citnw)){
citnw = delete_vertex_attr(citnw,attr)
}
}
write_graph(citnw,file=exportfile,format = 'gml')
}
# export
export_gml(citationcorehigher,'../../Data/Processed/core_evurbth.gml')
getwd()
